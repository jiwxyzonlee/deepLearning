{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_dnn_ipynb_txt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juRJp_b4rIRk",
        "colab_type": "text"
      },
      "source": [
        "copy from:\n",
        "https://github.com/dhrim/joongang_2020_03/blob/master/material/deep_learning/dnn_mnist.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH--ADDvhXQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY37KleXmoaY",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BEmcWKsmj6V",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46F5aLlSlz6G",
        "colab_type": "code",
        "outputId": "8ab23e70-9de3-4d0e-843c-d5657d5a0e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGtQOq_Pl_Hp",
        "colab_type": "code",
        "outputId": "b1b512e2-ba8c-48da-cf49-33d5792a15d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(raw_train_x.shape)\n",
        "print(raw_train_y.shape)\n",
        "print(raw_test_x.shape)\n",
        "print(raw_test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpQVipLzNlMP",
        "colab_type": "code",
        "outputId": "83cac48e-2102-4848-a9d4-2663212f20e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(raw_train_y[0])\n",
        "print(raw_train_x[0])\n",
        "# 0~253? 255? 밝기 정도"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRvTcjrwyMAB",
        "colab_type": "code",
        "outputId": "2ea2d012-182d-4c57-e419-e061e20a500c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(4):\n",
        "  print(raw_train_y[i])\n",
        "  plt.imshow(raw_train_x[i], cmap=plt.cm.binary)\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm1cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/D8K28WFOQm56wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6AV1QI6mewE",
        "colab_type": "text"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBZsXbAjmNiC",
        "colab_type": "code",
        "outputId": "3da90b0d-5b0a-4911-bcb3-40ff98042992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(np.max(raw_train_x[:,]))\n",
        "print(np.max(raw_test_x[:,]))\n",
        "\n",
        "train_x = raw_train_x/255\n",
        "test_x = raw_test_x/255\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y\n",
        "\n",
        "print(np.max(train_x[:,]))\n",
        "print(np.max(test_x[:,]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "255\n",
            "255\n",
            "1.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_38v16ommum-",
        "colab_type": "code",
        "outputId": "a2d47509-b8d7-4bc4-a5dc-322aa54e3caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "data_count = train_x.shape[0]\n",
        "data_size = train_x.shape[1]*train_x.shape[2]\n",
        "train_x = train_x.reshape((data_count, data_size))\n",
        "\n",
        "data_count = test_x.shape[0]\n",
        "test_x = test_x.reshape((data_count, data_size))\n",
        "\n",
        "print(train_x.shape)\n",
        "print(test_x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeG7foCfu1PF",
        "colab_type": "text"
      },
      "source": [
        "# 모델 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X08W3R4_ldKc",
        "colab_type": "code",
        "outputId": "de1170b8-793d-4cbb-b7c0-b9a81bf6c437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "# model.add(Dense(10, activation='relu', input_shape=(4,)))\n",
        "model.add(Dense(10, activation='relu', input_shape=(28*28,))) #mnist\n",
        "model.add(Dense(10, activation='relu'))\n",
        "# model.add(Dense(3, activation='softmax'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igZrWG5nu7FK",
        "colab_type": "code",
        "outputId": "1a269c3f-c4ca-4a70-c74b-df3e9906dab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# start_time = time.time() # REMOVED\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "# print(\"elapsed : {}\".format(time.time() - start_time)) # REMOVED"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9770 - accuracy: 0.6882\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3888 - accuracy: 0.8884\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3188 - accuracy: 0.9084\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.9166\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2710 - accuracy: 0.9220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb220653c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiIqivhwu9Vi",
        "colab_type": "code",
        "outputId": "0698960c-9928-4371-fbe6-b3a930460e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2676 - accuracy: 0.9214\n",
            "loss= 0.26760169863700867\n",
            "acc= 0.9214000105857849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GCmG_ZVurfb",
        "colab_type": "code",
        "outputId": "e63398cf-17ef-4f11-97c5-9205f3a67dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_ = model.predict(test_x)\n",
        "print(y_) # 10개 (출력 노드의 숫자들)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "print(predicted)\n",
        "\n",
        "for i in range(4):\n",
        "  print(raw_test_y[i])\n",
        "  plt.imshow(raw_test_x[i], cmap=plt.cm.binary)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.02120543e-06 1.76762580e-04 1.22416578e-03 ... 9.86912489e-01\n",
            "  6.95958151e-05 7.72143528e-03]\n",
            " [1.80077109e-06 3.72319414e-06 9.97338235e-01 ... 1.03242951e-06\n",
            "  3.88561330e-06 4.17849696e-12]\n",
            " [1.79365292e-04 9.71846282e-01 7.51513662e-03 ... 2.40986678e-03\n",
            "  9.36319400e-03 2.88470183e-04]\n",
            " ...\n",
            " [3.90113577e-08 2.78004961e-07 9.72428170e-05 ... 7.14230584e-04\n",
            "  3.45121865e-04 4.99651842e-02]\n",
            " [2.04723929e-05 2.68797012e-05 4.30363798e-05 ... 7.80570844e-08\n",
            "  1.14344675e-02 3.16483101e-06]\n",
            " [1.97897916e-05 8.74357618e-12 8.04324372e-05 ... 5.47762842e-11\n",
            "  8.02580313e-09 8.04847047e-14]]\n",
            "[7 2 1 ... 4 5 6]\n",
            "7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5fbVYvAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJAg7kARhB5Ig7EAS/w+xTgZkgsfn/QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAMFklEQVR4nO3dXagc9R3G8ecxjQhJwdgsIUTpsSIR\nKTSRJRQqahFLIkKMEG0uNAUhvVBJQbDSXtRLkapUKUJaY9LSKoUajKBtbRBfIEhWzZuKL5UTmpCX\nDQq1emGjv16cUY7x7OzJzuzOJr/vB5adnf/OmYclT2Z3Zs/5OyIE4Mx3VtMBAIwGZQeSoOxAEpQd\nSIKyA0l8Y5Q7W7hwYUxMTIxyl0Aqk5OTOn78uGcaq1R22ysl/UbSHEm/j4h7y54/MTGhTqdTZZcA\nSrTb7Z5jA7+Ntz1H0m8lrZJ0qaR1ti8d9OcBGK4qn9lXSHovIt6PiE8lPSFpdT2xANStStmXSPr3\ntMcHi3VfYXuD7Y7tTrfbrbA7AFUM/Wx8RGyKiHZEtFut1rB3B6CHKmU/JOmCaY/PL9YBGENVyr5L\n0sW2L7R9tqQfS9peTywAdRv40ltEnLB9u6S/a+rS2+aIeKO2ZABqVek6e0Q8I+mZmrIAGCK+Lgsk\nQdmBJCg7kARlB5Kg7EASlB1IgrIDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJUHYgCcoO\nJEHZgSQoO5AEZQeSoOxAEiOdshn5vPPOOz3Hli5dWrrtQw89VDp+xx13DJQpK47sQBKUHUiCsgNJ\nUHYgCcoOJEHZgSQoO5AE19kxVK+//nrPsbPOKj/WLFmypO44qVUqu+1JSR9J+kzSiYho1xEKQP3q\nOLL/MCKO1/BzAAwRn9mBJKqWPST9w/artjfM9ATbG2x3bHe63W7F3QEYVNWyXx4Rl0laJek221ec\n/ISI2BQR7Yhot1qtirsDMKhKZY+IQ8X9MUnbJK2oIxSA+g1cdtvzbH/zi2VJP5K0v65gAOpV5Wz8\nIknbbH/xc/4cEX+rJRXOGLt37+45Nn/+/NJtb7jhhrrjpDZw2SPifUnfqzELgCHi0huQBGUHkqDs\nQBKUHUiCsgNJ8CuuqGTfvn2l4w8//HDPsVtuuaXuOCjBkR1IgrIDSVB2IAnKDiRB2YEkKDuQBGUH\nkuA6Oyp5++23S8c//vjjnmM33XRT3XFQgiM7kARlB5Kg7EASlB1IgrIDSVB2IAnKDiTBdXZUct99\n95WOT0xM9Bxrt5n0d5Q4sgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAElxnR6nJycnS8V27dpWOL126\ntOfYvHnzBomEAfU9stvebPuY7f3T1p1n+znb7xb3C4YbE0BVs3kbv0XSypPW3S1pR0RcLGlH8RjA\nGOtb9oh4UdIHJ61eLWlrsbxV0vU15wJQs0FP0C2KiMPF8hFJi3o90fYG2x3bnW63O+DuAFRV+Wx8\nRISkKBnfFBHtiGi3Wq2quwMwoEHLftT2Ykkq7o/VFwnAMAxa9u2S1hfL6yU9VU8cAMPS9zq77ccl\nXSVpoe2Dkn4l6V5Jf7F9q6QDkm4cZkg054UXXqi0PR/dxkffskfEuh5DV9ecBcAQ8XVZIAnKDiRB\n2YEkKDuQBGUHkuBXXFFq7969lba/6667akqCqjiyA0lQdiAJyg4kQdmBJCg7kARlB5Kg7EASXGdP\nbufOnaXjjz32WOn48uXLS8evueaaU86E4eDIDiRB2YEkKDuQBGUHkqDsQBKUHUiCsgNJcJ09uR07\ndpSOf/jhh6XjK1eePOfnV51zzjmnnAnDwZEdSIKyA0lQdiAJyg4kQdmBJCg7kARlB5LgOntye/bs\nqbT92rVra0qCYet7ZLe92fYx2/unrbvH9iHbu4vbtcONCaCq2byN3yJppq9JPRgRy4rbM/XGAlC3\nvmWPiBclfTCCLACGqMoJuttt7y3e5i/o9STbG2x3bHe63W6F3QGoYtCyPyLpIknLJB2WdH+vJ0bE\npohoR0S71WoNuDsAVQ1U9og4GhGfRcTnkn4naUW9sQDUbaCy21487eEaSft7PRfAeOh7nd3245Ku\nkrTQ9kFJv5J0le1lkkLSpKSfDjEjKjhy5Ejp+EsvvVQ6fskll5SOr1mz5pQzoRl9yx4R62ZY/egQ\nsgAYIr4uCyRB2YEkKDuQBGUHkqDsQBL8iusZbsuWLaXjR48eLR1ftWpVjWnQJI7sQBKUHUiCsgNJ\nUHYgCcoOJEHZgSQoO5AE19nPcAcOHKi0/YIFPf/iGE4zHNmBJCg7kARlB5Kg7EASlB1IgrIDSVB2\nIAmus5/hnn766UrbX3fddTUlQdM4sgNJUHYgCcoOJEHZgSQoO5AEZQeSoOxAElxnPwOUTbvc7+/C\nI4++R3bbF9h+3vabtt+wvbFYf57t52y/W9zzVw6AMTabt/EnJN0ZEZdK+r6k22xfKuluSTsi4mJJ\nO4rHAMZU37JHxOGIeK1Y/kjSW5KWSFotaWvxtK2Srh9WSADVndIJOtsTkpZLekXSoog4XAwdkbSo\nxzYbbHdsd7rdboWoAKqYddltz5f0V0k/i4j/TB+LiJAUM20XEZsioh0R7VarVSksgMHNquy252qq\n6H+KiCeL1UdtLy7GF0s6NpyIAOrQ99KbbUt6VNJbEfHAtKHtktZLure4f2ooCdHXtm3beo6dOHGi\ndNvly5eXjl955ZUDZcL4mc119h9IulnSPtu7i3W/0FTJ/2L7VkkHJN04nIgA6tC37BHxsiT3GL66\n3jgAhoWvywJJUHYgCcoOJEHZgSQoO5AEv+J6Gvjkk09Kx5999tmBf/batWtLx+fMmTPwz8Z44cgO\nJEHZgSQoO5AEZQeSoOxAEpQdSIKyA0lwnf00MHfu3NLxc889t+fY6tWrS7fduHHjQJlw+uHIDiRB\n2YEkKDuQBGUHkqDsQBKUHUiCsgNJcJ39NNDvOvvOnTtHlASnM47sQBKUHUiCsgNJUHYgCcoOJEHZ\ngSQoO5BE37LbvsD287bftP2G7Y3F+ntsH7K9u7hdO/y4AAY1my/VnJB0Z0S8Zvubkl61/Vwx9mBE\n/Hp48QDUZTbzsx+WdLhY/sj2W5KWDDsYgHqd0md22xOSlkt6pVh1u+29tjfbXtBjmw22O7Y73W63\nUlgAg5t12W3Pl/RXST+LiP9IekTSRZKWaerIf/9M20XEpohoR0S71WrVEBnAIGZVdttzNVX0P0XE\nk5IUEUcj4rOI+FzS7yStGF5MAFXN5my8JT0q6a2IeGDa+sXTnrZG0v764wGoy2zOxv9A0s2S9tne\nXaz7haR1tpdJCkmTkn46lIQAajGbs/EvS/IMQ8/UHwfAsPANOiAJyg4kQdmBJCg7kARlB5Kg7EAS\nlB1IgrIDSVB2IAnKDiRB2YEkKDuQBGUHkqDsQBKOiNHtzO5KOjBt1UJJx0cW4NSMa7ZxzSWRbVB1\nZvt2RMz4999GWvav7dzuRES7sQAlxjXbuOaSyDaoUWXjbTyQBGUHkmi67Jsa3n+Zcc02rrkksg1q\nJNka/cwOYHSaPrIDGBHKDiTRSNltr7T9tu33bN/dRIZebE/a3ldMQ91pOMtm28ds75+27jzbz9l+\nt7ifcY69hrKNxTTeJdOMN/raNT39+cg/s9ueI+kdSddIOihpl6R1EfHmSIP0YHtSUjsiGv8Chu0r\nJP1X0h8i4rvFuvskfRAR9xb/US6IiJ+PSbZ7JP236Wm8i9mKFk+fZlzS9ZJ+ogZfu5JcN2oEr1sT\nR/YVkt6LiPcj4lNJT0ha3UCOsRcRL0r64KTVqyVtLZa3auofy8j1yDYWIuJwRLxWLH8k6Ytpxht9\n7UpyjUQTZV8i6d/THh/UeM33HpL+YftV2xuaDjODRRFxuFg+ImlRk2Fm0Hca71E6aZrxsXntBpn+\nvCpO0H3d5RFxmaRVkm4r3q6OpZj6DDZO105nNY33qMwwzfiXmnztBp3+vKomyn5I0gXTHp9frBsL\nEXGouD8maZvGbyrqo1/MoFvcH2s4z5fGaRrvmaYZ1xi8dk1Of95E2XdJutj2hbbPlvRjSdsbyPE1\ntucVJ05ke56kH2n8pqLeLml9sbxe0lMNZvmKcZnGu9c042r4tWt8+vOIGPlN0rWaOiP/L0m/bCJD\nj1zfkbSnuL3RdDZJj2vqbd3/NHVu41ZJ35K0Q9K7kv4p6bwxyvZHSfsk7dVUsRY3lO1yTb1F3ytp\nd3G7tunXriTXSF43vi4LJMEJOiAJyg4kQdmBJCg7kARlB5Kg7EASlB1I4v9JKKc5kJ16eQAAAABJ\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEIQdCOL/AZn3METKQC3GAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c503DSvxvOU5",
        "colab_type": "text"
      },
      "source": [
        "# 한눈에 모아보면"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSNPBq4kvR9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeBqmrvcwXDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = raw_train_x/255\n",
        "test_x = raw_test_x/255\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y\n",
        "\n",
        "train_x = train_x.reshape((60000, 28*28))\n",
        "test_x = test_x.reshape((10000, 28*28))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tksmYhZswCac",
        "colab_type": "code",
        "outputId": "ec203a20-16bb-4bad-8811-cb5399be81e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(28*28,)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.9044 - acc: 0.7136\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.3927 - acc: 0.8880\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.3307 - acc: 0.9058\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.2990 - acc: 0.9147\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2777 - acc: 0.9197\n",
            "10000/10000 [==============================] - 0s 28us/sample - loss: 0.2660 - acc: 0.9234\n",
            "loss= 0.26598617191910745\n",
            "acc= 0.9234\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63C6TPhfxCHQ",
        "colab_type": "text"
      },
      "source": [
        "# Flatten 레이어 사용\n",
        "\n",
        "(None, 28, 28) shape의 train_x를 그대로 사용.\n",
        "\n",
        "모델의 처음에 Flatten() 레이어를 두어, 입력 모양을 변경한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8M2QsSUxGZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98Ly9UIFxIjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(raw_train_x, raw_train_y), (raw_test_x, raw_test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = raw_train_x/255\n",
        "test_x = raw_test_x/255\n",
        "\n",
        "train_y = raw_train_y\n",
        "test_y = raw_test_y\n",
        "\n",
        "# data_count = train_x.shape[0] # COMMENT OUT\n",
        "# data_size = train_x.shape[1]*train_x.shape[2] # COMMENT OUT\n",
        "# train_x = train_x.reshape((data_count, data_size)) # COMMENT OUT\n",
        "\n",
        "# data_count = test_x.shape[0] # COMMENT OUT\n",
        "# test_x = test_x.reshape((data_count, data_size)) # COMMENT OUT\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ-hK0S5xIl7",
        "colab_type": "code",
        "outputId": "d84aa021-4dd7-48b2-977a-05a0efc53eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28))) # ADD (Flatten: keras에서, 받은 입력을 한 줄로 펴줌)\n",
        "# model.add(Dense(10, activation='relu', input_shape=(28*28,)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9560 - accuracy: 0.6982\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4043 - accuracy: 0.8855\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.9037\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2974 - accuracy: 0.9142\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2699 - accuracy: 0.9228\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.9249\n",
            "loss= 0.2637695074081421\n",
            "acc= 0.9248999953269958\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXuXR4tSBRPu",
        "colab_type": "text"
      },
      "source": [
        "# DNN classification Template"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfdEDwzKBUnT",
        "colab_type": "code",
        "outputId": "fd48090f-f429-48d7-b6ee-e6fc9f53e0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_x = train_x/255\n",
        "test_x = test_x/255\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.9516 - accuracy: 0.6962\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3635 - accuracy: 0.8978\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.9117\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2860 - accuracy: 0.9179\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2686 - accuracy: 0.9223\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.9232\n",
            "loss= 0.26137682795524597\n",
            "acc= 0.9232000112533569\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ferd_0Cx93Fb",
        "colab_type": "text"
      },
      "source": [
        "# Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfBfbJqOyIkL",
        "colab_type": "text"
      },
      "source": [
        "## Normalization을 하지 않으면\n",
        "\n",
        "위에서는 0 ~ 255의 값을 0 ~ 1로 normalization하여 학습했다.\n",
        "\n",
        "이 과정을 생략하고 그대로 실행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0BQDjm2yYpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# train_x = train_x/255\n",
        "# test_x = test_x/255\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlMkT8axIoi",
        "colab_type": "code",
        "outputId": "1f0ff1a3-3b47-4cee-fc5d-f10f0b46b573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 2.4654 - acc: 0.1538\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 1.9504 - acc: 0.2509\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 1.7553 - acc: 0.3037\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6404 - acc: 0.3354\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5597 - acc: 0.3471\n",
            "10000/10000 [==============================] - 0s 26us/sample - loss: 1.5352 - acc: 0.3417\n",
            "loss= 1.5351685056686402\n",
            "acc= 0.3417\n",
            "[9 6 1 ... 9 2 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_H2aV8qy0Im",
        "colab_type": "text"
      },
      "source": [
        "학습이 진행되지만 normalization했을 때와 비교하면 더디게 진행된다. (수렴이 느려짐)\n",
        "\n",
        "아래는 0~1로 normalization을 했을 때\n",
        "```\n",
        "Epoch 1/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.8862 - acc: 0.7278\n",
        "Epoch 2/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3659 - acc: 0.8950\n",
        "Epoch 3/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3164 - acc: 0.9100\n",
        "Epoch 4/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2904 - acc: 0.9171\n",
        "Epoch 5/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2724 - acc: 0.9225\n",
        "10000/10000 [==============================] - 0s 27us/sample - loss: 0.2613 - acc: 0.9265\n",
        "loss= 0.26132496373653413\n",
        "acc= 0.9265\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki5TbWWT-DY7",
        "colab_type": "text"
      },
      "source": [
        "## -1 ~ 1로 Normalization 하면"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlldGHxzygP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# train_x = train_x/255\n",
        "# test_x = test_x/255\n",
        "train_x = train_x/127.5 - 1\n",
        "test_x = test_x/127.5 - 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Evje8DO-MmC",
        "colab_type": "code",
        "outputId": "a8663ac9-8669-4948-d71b-8d23c6855fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 1.3357 - acc: 0.5336\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.7027 - acc: 0.7702\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.6038 - acc: 0.8077\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.5583 - acc: 0.8249\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.5221 - acc: 0.8389\n",
            "10000/10000 [==============================] - 0s 29us/sample - loss: 0.4942 - acc: 0.8463\n",
            "loss= 0.49422486678361893\n",
            "acc= 0.8463\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kacaLSWw_DSE",
        "colab_type": "text"
      },
      "source": [
        "학습이 진행되지만 normalization했을 때와 비교하면 더디게 진행된다.\n",
        "\n",
        "아래는 0~1로 normalization을 했을 때\n",
        "```\n",
        "Epoch 1/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.8862 - acc: 0.7278\n",
        "Epoch 2/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3659 - acc: 0.8950\n",
        "Epoch 3/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3164 - acc: 0.9100\n",
        "Epoch 4/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2904 - acc: 0.9171\n",
        "Epoch 5/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2724 - acc: 0.9225\n",
        "10000/10000 [==============================] - 0s 27us/sample - loss: 0.2613 - acc: 0.9265\n",
        "loss= 0.26132496373653413\n",
        "acc= 0.9265\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZyRDXoX_Stx",
        "colab_type": "text"
      },
      "source": [
        "## -255 ~ 255로 하면"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVcxZIVr-mJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# train_x = train_x/255\n",
        "# test_x = test_x/255\n",
        "train_x = train_x*2 - 255\n",
        "test_x = test_x*2 - 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT09nVdp_ZFX",
        "colab_type": "code",
        "outputId": "cf657248-597a-4670-fbde-99017558e389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 4.1636 - acc: 0.1091\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 2.3027 - acc: 0.1123\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 2.3011 - acc: 0.1126\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 16us/sample - loss: 2.2933 - acc: 0.1176\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 17us/sample - loss: 2.1994 - acc: 0.1655\n",
            "10000/10000 [==============================] - 0s 27us/sample - loss: 2.1274 - acc: 0.1931\n",
            "loss= 2.127422957611084\n",
            "acc= 0.1931\n",
            "[1 2 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXRsbuhi_fxp",
        "colab_type": "text"
      },
      "source": [
        "학습이 진행되지만 normalization 안했을 때 보다 더디게 진행된다.\n",
        "\n",
        "아래는 normalization을 안했을 때\n",
        "```\n",
        "Epoch 1/5\n",
        "60000/60000 [==============================] - 1s 18us/sample - loss: 2.4654 - acc: 0.1538\n",
        "Epoch 2/5\n",
        "60000/60000 [==============================] - 1s 19us/sample - loss: 1.9504 - acc: 0.2509\n",
        "Epoch 3/5\n",
        "60000/60000 [==============================] - 1s 17us/sample - loss: 1.7553 - acc: 0.3037\n",
        "Epoch 4/5\n",
        "60000/60000 [==============================] - 1s 18us/sample - loss: 1.6404 - acc: 0.3354\n",
        "Epoch 5/5\n",
        "60000/60000 [==============================] - 1s 18us/sample - loss: 1.5597 - acc: 0.3471\n",
        "10000/10000 [==============================] - 0s 26us/sample - loss: 1.5352 - acc: 0.3417\n",
        "loss= 1.5351685056686402\n",
        "acc= 0.3417\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLZWVTr_Abcy",
        "colab_type": "text"
      },
      "source": [
        "## 0 ~ 0.5로 하면"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xE5wv_w_ceD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# train_x = train_x/255\n",
        "# test_x = test_x/255\n",
        "train_x = train_x/255/2\n",
        "test_x = test_x/255/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFyXibot_1Ng",
        "colab_type": "code",
        "outputId": "ba47fca6-e316-4233-d89f-5fb5531dbbad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_6 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 20us/sample - loss: 1.0266 - acc: 0.6823\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.4344 - acc: 0.8783\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3587 - acc: 0.8995\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 18us/sample - loss: 0.3184 - acc: 0.9108\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2932 - acc: 0.9169\n",
            "10000/10000 [==============================] - 0s 31us/sample - loss: 0.2841 - acc: 0.9174\n",
            "loss= 0.28412638966143133\n",
            "acc= 0.9174\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsHcOKyP_9T3",
        "colab_type": "text"
      },
      "source": [
        "학습이 되며 0~1로 normalization했을 때 보다 살짝 더디다\n",
        "\n",
        "아래는 0~1로 normalization을 했을 때\n",
        "```\n",
        "Epoch 1/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.8862 - acc: 0.7278\n",
        "Epoch 2/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3659 - acc: 0.8950\n",
        "Epoch 3/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3164 - acc: 0.9100\n",
        "Epoch 4/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2904 - acc: 0.9171\n",
        "Epoch 5/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2724 - acc: 0.9225\n",
        "10000/10000 [==============================] - 0s 27us/sample - loss: 0.2613 - acc: 0.9265\n",
        "loss= 0.26132496373653413\n",
        "acc= 0.9265\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Wm0dNTAuEb",
        "colab_type": "text"
      },
      "source": [
        "## 0 ~ 2로 하면"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EXcTUBy_5xN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# train_x = train_x/255\n",
        "# test_x = test_x/255\n",
        "train_x = train_x/255*2\n",
        "test_x = test_x/255*2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cKj6SChAxPz",
        "colab_type": "code",
        "outputId": "c14077b6-c3d9-41b9-acb9-e07a9fa33edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(train_x, train_y, epochs=5, verbose=1, batch_size=128)\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(test_x, test_y)\n",
        "print(\"loss=\",loss)\n",
        "print(\"acc=\",acc)\n",
        "\n",
        "y_ = model.predict(test_x)\n",
        "predicted = np.argmax(y_, axis=1)\n",
        "\n",
        "print(predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_7 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 8,070\n",
            "Trainable params: 8,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 1s 21us/sample - loss: 0.7630 - acc: 0.7654\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.3363 - acc: 0.9045\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2965 - acc: 0.9152\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2724 - acc: 0.9212\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 1s 19us/sample - loss: 0.2548 - acc: 0.9267\n",
            "10000/10000 [==============================] - 0s 31us/sample - loss: 0.2541 - acc: 0.9268\n",
            "loss= 0.25408969558775424\n",
            "acc= 0.9268\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14ZadaUTA3Qd",
        "colab_type": "text"
      },
      "source": [
        "학습이 되며 0~1로 normalization했을 때 보다 살짝 빠르다\n",
        "\n",
        "아래는 0~1로 normalization을 했을 때\n",
        "```\n",
        "Epoch 1/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.8862 - acc: 0.7278\n",
        "Epoch 2/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3659 - acc: 0.8950\n",
        "Epoch 3/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.3164 - acc: 0.9100\n",
        "Epoch 4/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2904 - acc: 0.9171\n",
        "Epoch 5/5\n",
        "60000/60000 [==============================] - 1s 20us/sample - loss: 0.2724 - acc: 0.9225\n",
        "10000/10000 [==============================] - 0s 27us/sample - loss: 0.2613 - acc: 0.9265\n",
        "loss= 0.26132496373653413\n",
        "acc= 0.9265\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz6YSQUnA0fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}