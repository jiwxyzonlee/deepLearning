{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "py0325",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyCH6mB3ECXA",
        "colab_type": "code",
        "outputId": "b00b3131-4231-45ab-f313-fb4fa7df0d57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "#mnist01.py\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 숫자 이미지 파일을 MNIST_data 폴더에 다운로드\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "# 임의로 1개의 파일을 구해옴\n",
        "batch_xs, batch_ys = mnist.train.next_batch(1)\n",
        "# print(batch_xs.shape)\n",
        "# print(batch_ys.shape)\n",
        "# print(batch_xs.reshape(28,28))\n",
        "#print(batch_xs)\n",
        "print(batch_ys)\n",
        "\n",
        "# 1장의 이미지는 28 * 28 개의 픽셀로 되어있음\n",
        "plt.imshow(batch_xs.reshape(28,28), cmap='Greys')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg4EQdiBIAg7EARhB4Ig7EAQhB0I4v8B3CIy/FNAwjoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hccJAD3vH5Z7",
        "colab_type": "code",
        "outputId": "beeff8c9-2157-4290-a0b0-19e6985db130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "#mnist02.py\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 난수 시드값 설정하지 않으면 결과가 매번 달라질 수 있음\n",
        "tf.set_random_seed(777) # for reproducibility\n",
        "\n",
        "# Check out https://www.tensorflow.org/get_started/mnist/beginners\n",
        "# for more information about the mnist dataset\n",
        "# 자동으로 이미지를 다운로드\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "# 클래스 갯수: 숫자 이미지 파일 갯수\n",
        "nb_classes = 10\n",
        "\n",
        "# MNIST data image of shape 28 * 28 = 784\n",
        "X = tf.placeholder(tf.float32, [None, 784]) # 784행\n",
        "\n",
        "# 0 - 9 digits recognition = 10 classes\n",
        "Y = tf.placeholder(tf.float32, [None, nb_classes]) # 10열\n",
        "\n",
        "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
        "b = tf.Variable(tf.random_normal([nb_classes]))\n",
        "\n",
        "# Hypothesis (using softmax)\n",
        "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "\n",
        "# Test model\n",
        "# arg_max(): one-hot-encoding을 만들어 주는 함수(가장 확률이 높은것을 1로, 나머지는 0으로 만듬)\n",
        "# 10개의 예측값중에서 가장큰값을 구함\n",
        "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
        "\n",
        "# Calculate accuracy\n",
        "# float형으로 형변환 (정확도 구함)\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "# parameters (550번 학습한 것이 1 epoch?)\n",
        "training_epochs = 15\n",
        "batch_size = 100 # batch_size : 큰 파일을 나눠서 읽어옴 (100개) - 메모리가 부족하기 때문에\n",
        "# 55000 / 100 = 550\n",
        "# epoch : 반복횟수(1번 다 읽어온것)\n",
        "print('데이터 갯수=', mnist.train.num_examples) # 55,000 개\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  # Initialize TensorFlow variables\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  # Training cycle\n",
        "  # 전체 총 학습 횟수는 15회\n",
        "  for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(mnist.train.num_examples / batch_size)\n",
        "    # 55,000개를 이미지 100개씩 나눈 550번개 batch를 학습한 1회가 1 epoch, 15 epoch 수행\n",
        "    # epoch = 1\n",
        "    # total_batch = 550\n",
        "    # batch_size = 100 (한 번에 가져오는 이미지 개수)\n",
        "    for i in range(total_batch):\n",
        "      batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "      c, _ = sess.run([cost, optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
        "      avg_cost += c / total_batch\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "  print(\"Learning finished\")\n",
        "  \n",
        "  # Test the model using test sets\n",
        "  print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
        "  \n",
        "  # Get one and predict\n",
        "  r = random.randint(0, mnist.test.num_examples - 1)\n",
        "  print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
        "  print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
        "  \n",
        "  # don't know why this makes Travis Build error.\n",
        "  plt.imshow(\n",
        "      mnist.test.images[r:r + 1].reshape(28, 28)\n",
        "      ,cmap='Greys'\n",
        "      ,interpolation='nearest'\n",
        "      )\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "데이터 갯수= 55000\n",
            "Epoch: 0001 cost = 2.567894170\n",
            "Epoch: 0002 cost = 1.057073266\n",
            "Epoch: 0003 cost = 0.852373443\n",
            "Epoch: 0004 cost = 0.751388038\n",
            "Epoch: 0005 cost = 0.686439342\n",
            "Epoch: 0006 cost = 0.640169768\n",
            "Epoch: 0007 cost = 0.605904830\n",
            "Epoch: 0008 cost = 0.577114295\n",
            "Epoch: 0009 cost = 0.553933743\n",
            "Epoch: 0010 cost = 0.534603617\n",
            "Epoch: 0011 cost = 0.517797836\n",
            "Epoch: 0012 cost = 0.503041444\n",
            "Epoch: 0013 cost = 0.489816915\n",
            "Epoch: 0014 cost = 0.478698714\n",
            "Epoch: 0015 cost = 0.467733404\n",
            "Learning finished\n",
            "Accuracy:  0.8898\n",
            "Label:  [2]\n",
            "Prediction:  [8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIKwA0H8H3LzUkJ3CXR0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE1G0EsbH5cK",
        "colab_type": "code",
        "outputId": "d082038d-10bf-4938-9ea9-4837edb2050b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#tb_mul.py\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# 상수 선언\n",
        "a = tf.constant(20, name=\"a\")\n",
        "b = tf.constant(30, name=\"b\")\n",
        "mul = a * b\n",
        "\n",
        "# 세션 생성하기\n",
        "sess = tf.Session()\n",
        "\n",
        "# tensorboard 사용하기\n",
        "# tensorboard 로그가 저장될 폴더(log_dir)가 생성된다.\n",
        "tw = tf.summary.FileWriter(\"log_dir\", graph=sess.graph)\n",
        "\n",
        "# 세션 실행하기\n",
        "print(sess.run(mul))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK-OyZDCdb-V",
        "colab_type": "text"
      },
      "source": [
        "TensorBoard 사용법\n",
        "\n",
        "1. 이전 예제의 tensorboard 로그 파일을 삭제한다.\n",
        ">\n",
        "> c:\\> cd C:\\pythonwork\\python3\\tensorflow\\src\\ch05\\log_dir\n",
        "> \n",
        "> c:\\> del *.*\n",
        "\n",
        "2. tensorflow 예제 파일 생성/실행 한다. (tb_add.py)\n",
        ">\n",
        "> C:\\pythonwork\\python3\\tensorflow\\src\\ch05\\log_dir 디렉토리가 생성되고,\n",
        ">\n",
        "> log_dir디렉토리 안에 tensorboard 로그 파일이 생성됨\n",
        "\n",
        "3. 콘솔창에서 log_dir 디렉토리 이전 디렉토리 까지 이동후 tensorboard를 실행한다.\n",
        ">\n",
        "> c:\\> cd c:\\pythonwork\\python3\\tensorflow\\src\\ch05\n",
        ">\n",
        "> c:\\> tensorboard --logdir = log_dir <-- tensorboard 실행\n",
        "\n",
        "4. 웹브라우저에 다음 http://localhost:6006 입력후 실행한다.\n",
        ">\n",
        "> ( 잘 실행되지 않는 경우에는 chrome, firefox 웹브라우저로 실행 해본다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmWXZ4Z7p5Ur",
        "colab_type": "text"
      },
      "source": [
        "https://playground.tensorflow.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwk50sR7H5ei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "1caac815-3a3f-4d97-d989-9544158c61ec"
      },
      "source": [
        "#classification.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.set_random_seed(777)\n",
        "\n",
        "# 학습에 사용할 데이터 정의\n",
        "# 털과 날개가 있느냐를 담은 특징 데이터를 구성한다.(있으면1, 없으면 0)\n",
        "# [털, 날개]\n",
        "x_data = np.array(\n",
        "    [[0, 0], [1, 0], [1, 1], [0, 0], [0, 0], [0, 1]]\n",
        "    )\n",
        "\n",
        "# 1) 각 개체가 실제 어떤 종류인지를 나타내는 레이블(분류값) 데이터를 구성합니다.\n",
        "# 2)위에서 정의한 특징 데이터의 각 개체가 포유류인지 조류인지, 아니면 제3의 종류인지를\n",
        "# 기록한 실제 결과값이다.\n",
        "# 3)다음과 같은 형식을 one-hot 형식의 데이터라고 합니다.\n",
        "# 4)원-핫 인코딩(one-hot encoding)이란 데이터가 가질 수 있는 값들을 일렬로 나열한 배열을\n",
        "# 만들고, 그중 표현하려는 값을 뜻하는 인덱스의 원소만 1로 표기하고 나머지 원소는 모두 0으로\n",
        "# 채우는 표기법입니다.\n",
        "# 5)예를 들어, 우리가 판별하고자 하는 개체의 종류는 기타, 포유류, 조류 이렇게 세 가지 이고,\n",
        "# 이를 배열에 넣으면 [기타, 포유류, 조류]처럼 될 것이다.\n",
        "# 6)각 종류의 인덱스는 기타=0, 포유류=1, 조류=2가 되겠죠. 이를 원-핫-인코딩 형식으로 만들면\n",
        "# 다음처럼 된다.\n",
        "\n",
        "# [기타, 포유류, 조류]\n",
        "y_data = np.array([\n",
        "                   # 기타\n",
        "                   [1, 0, 0]\n",
        "                   # 포유류\n",
        "                   , [0, 1, 0]\n",
        "                   # 조류\n",
        "                   , [0, 0, 1]\n",
        "                   # 기타\n",
        "                   , [1, 0, 0]\n",
        "                   # 기타\n",
        "                   , [1, 0, 0]\n",
        "                   # 조류\n",
        "                   , [0, 0, 1]\n",
        "                   ])\n",
        "\n",
        "####################\n",
        "# 신경망 모델 구성\n",
        "####################\n",
        "# 특징 X와 레이블 Y와의 관계를 알아내는 모델입니다.\n",
        "# 플레이스홀더 X, Y 설정\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "# 신경망은 2차원으로\n",
        "# 가중치 변수 W는 [입력층(특징 수), 출력층(레이블 수)] -> [2, 3] 으로 설정\n",
        "W = tf.Variable(tf.random_uniform([2, 3], -1., 1.))\n",
        "# 편향을 각각 각 레이어의 아웃풋 갯수로 설정합니다.\n",
        "# 편향은 아웃풋의 갯수, 즉 최종 결과값의 분류 갯수인 3으로 설정합니다.\n",
        "# 편향 변수 b는 레이블 수인 3개의 요소를 가진 변수로 설정\n",
        "b = tf.Variable(tf.zeros([3]))\n",
        "\n",
        "# 신경망에 가중치 W과 편향 b을 적용합니다\n",
        "L = tf.add(tf.matmul(X, W), b)\n",
        "# 가중치와 편향을 이용해 계산한 결과 값에\n",
        "# 텐서플로우에서 기본적으로 제공하는 활성화 함수인 ReLU 함수를 적용합니다.\n",
        "# hidden Layer 하나 추가한다고 생각하면 됨(이 순간부터 딥러닝!)\n",
        "L = tf.nn.relu(L)\n",
        "# 마지막으로 softmax 함수를 이용하여 출력값을 사용하기 쉽게 만듭니다\n",
        "# softmax 함수는 다음처럼 결과값을 전체합이 1인 확률로 만들어주는 함수입니다.\n",
        "# 예) [8.04, 2.76, -6.52] -> [0.53 0.24 0.23]\n",
        "model = tf.nn.softmax(L)\n",
        "\n",
        "# 신경망을 최적화하기 위한 비용 함수를 작성합니다.\n",
        "# 각 개별 결과에 대한 합을 구한 뒤 평균을 내는 방식을 사용합니다.\n",
        "# 전체 합이 아닌, 개별 결과를 구한 뒤 평균을 내는 방식을 사용하기 위해 axis 옵션을 사용합니다.\n",
        "# axis 옵션이 없으면 -1.09 처럼 총합인 스칼라값으로 출력됩니다.\n",
        "# Y model Y * tf.log(model) reduce_sum(axis=1)\n",
        "# 예) [[1 0 0] [[0.1 0.7 0.2] -> [[-1.0 0 0] -> [-1.0, -0.09]\n",
        "# [0 1 0]] [0.2 0.8 0.0]] [ 0 -0.09 0]]\n",
        "# 즉, 이것은 예측값과 실제값 사이의 확률 분포의 차이를 비용으로 계산한 것이며,\n",
        "# 이것을 교차 엔트로피(Cross-Entropy) 라고 합니다.\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(model), axis=1))\n",
        "# 경사하강법으로 비용을 최적화합니다.\n",
        "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "# 경사하강법보다 성능이 좋은 AdamOptimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "train_op = optimizer.minimize(cost)\n",
        "\n",
        "####################\n",
        "# 신경망 모델 학습\n",
        "####################\n",
        "# 텐서플로의 세션을 초기화\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "# 위에서 구성한 특징과 레이블 데이터를 이용해 100번 학습을 진행\n",
        "for step in range(100):\n",
        "  sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
        "  # 학습 도중에 10번에 한번씩 손실값을 출력함\n",
        "  if (step + 1) % 10 == 0:\n",
        "    print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
        "\n",
        "##############################\n",
        "# 결과 확인\n",
        "# 0: 기타 1: 포유류, 2: 조류\n",
        "#############################\n",
        "# 학습된 결과를 확인해보는 코드 작성\n",
        "# 1)예측값인 model을 바로 출력하면 [0.2, 0.7, 0.1]과 같이 확률로 나오기 때문에, 요소 중\n",
        "# 2)가장 큰 값의 인덱스를 찾아주는 argmax 함수를 사용하여 레이블 값을 출력\n",
        "# 3)tf.argmax: 예측값과 실제값의 행렬에서 tf.argmax 를 이용해 가장 큰 값을 가져옵니다.\n",
        "# 4)원-핫 인코딩을 거꾸로 한 결과를 만들어준다.\n",
        "# 예) [[0 1 0] [1 0 0]] -> [1 0]\n",
        "# [[0.2 0.7 0.1] [0.9 0.1 0.]] -> [1 0]\n",
        "prediction = tf.argmax(model, 1) # 예측값\n",
        "target = tf.argmax(Y, 1) # 실제값\n",
        "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
        "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
        "\n",
        "# 정확도 출력\n",
        "# 1)전체 학습 데이터에 대한 예측값과 실측값을 tf.equal()함수로 비교한 뒤,\n",
        "# true, false 값으로 나온 결과를 다시 tf.cast()함수를 이용해 0과 1로 바꾸어\n",
        "# 평균을 내면 간단히 정확도를 구할 수 있다.\n",
        "# 2)프로그램을 실행해서 학습을 시키면, 손실값이 점점 줄어드는 것을 확인할 수 있다.\n",
        "# 하지만, 실망스럽게도 아무리 학습횟수를 늘려도 정확도가 크게 높아지지 않는다.\n",
        "# 그 이유는 신경망이 한 층밖에 안 되기 때문인데, 하나의 층(hidden layer)을 더 늘리면\n",
        "# 정확도가 높아진다.\n",
        "is_correct = tf.equal(prediction, target)\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 0.9360135\n",
            "20 0.9149382\n",
            "30 0.9010996\n",
            "40 0.88978595\n",
            "50 0.87887526\n",
            "60 0.86920685\n",
            "70 0.86014694\n",
            "80 0.8514938\n",
            "90 0.8435934\n",
            "100 0.8360533\n",
            "예측값: [0 2 2 0 0 2]\n",
            "실제값: [0 1 2 0 0 2]\n",
            "정확도: 83.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioAtA8o_H5gy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "87dc4852-d3c5-4a43-c4e1-aa224afdaf22"
      },
      "source": [
        "#deepNN.py\n",
        "\n",
        "# 털과 날개가 있는지 없는지에 따라, 포유류인지 조류인지 분류하는 신경망 모델을 만들어봅니다.\n",
        "# 신경망의 레이어를 여러개로 구성하여 말로만 듣던 딥러닝을 구성해 봅시다!\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "# 학습에 사용할 데이터 정의\n",
        "# [털, 날개]\n",
        "x_data = np.array([[0, 0], [1, 0], [1, 1], [0, 0], [0, 0], [0, 1]])\n",
        "\n",
        "# 원-핫 인코딩(one-hot encoding)이란 데이터가 가질 수 있는 값들을 일렬로 나열한 배열을\n",
        "# 만들고, 그중 표현하려는 값을 뜻하는 인덱스의 원소만 1로 표기하고 나머지 원소는 모두 0으로\n",
        "# 채우는 표기법입니다.\n",
        "# [기타, 포유류, 조류]\n",
        "y_data = np.array([\n",
        "                   # 기타\n",
        "                   [1, 0, 0],\n",
        "                   # 포유류\n",
        "                   [0, 1, 0], \n",
        "                   # 조류\n",
        "                   [0, 0, 1],\n",
        "                   # 기타\n",
        "                   [1, 0, 0], \n",
        "                   # 기타\n",
        "                   [1, 0, 0], \n",
        "                   # 조류\n",
        "                   [0, 0, 1]\n",
        "                   ])\n",
        "\n",
        "#####################\n",
        "# 신경망 모델 구성\n",
        "#####################\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "# 다층 신경망을 만드는 것은, 앞에서 만든 단층 신경망 모델에 가중치와 편향을 추가해서 만든다.\n",
        "# 가중치\n",
        "# W1 = [2, 10] -> [특징, 은닉층의 뉴런수]\n",
        "# W2 = [10, 3] -> [은닉층의 뉴런수, 분류 수]\n",
        "# 편향\n",
        "# b1 = [10] -> 은닉층의 뉴런 수\n",
        "# b2 = [3] -> 분류 수\n",
        "# 입력층과 출력층은 각각 특징과 분류 갯수로 맞추고, 중간의 연결 부분은 맞닿은 층의 뉴런 수와\n",
        "# 같도록 맞추면 된다.\n",
        "# 중간의 연결 부분을 은닉층(hidden layer)이라 하며, 은닉층의 뉴런 수는 하이퍼파라미터이므로 실험을\n",
        "# 통해 가장 적절한 수를 정하면 된다.\n",
        "\n",
        "# 첫번째 가중치의 차원은 [특징, 히든 레이어의 뉴런갯수] -> [2, 10] 으로 정합니다.\n",
        "W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.))\n",
        "\n",
        "# 두번째 가중치의 차원을 [첫번째 히든 레이어의 뉴런 갯수, 분류 갯수] -> [10, 3] 으로 정합니다.\n",
        "W2 = tf.Variable(tf.random_uniform([10, 3], -1., 1.))\n",
        "\n",
        "# 편향을 각각 각 레이어의 아웃풋 갯수로 설정합니다.\n",
        "# b1 은 히든 레이어의 뉴런 갯수로, b2 는 최종 결과값 즉, 분류 갯수인 3으로 설정합니다.\n",
        "b1 = tf.Variable(tf.zeros([10])) # 은닉층의 뉴런 수\n",
        "b2 = tf.Variable(tf.zeros([3])) # 분류 수\n",
        "\n",
        "# 신경망의 히든 레이어에 가중치 W1과 편향 b1을 적용합니다\n",
        "# 특징 입력값에 첫번째 가중치와 편향, 그리고 활성화 함수를 적용합니다.\n",
        "L1 = tf.add(tf.matmul(X, W1), b1)\n",
        "L1 = tf.nn.relu(L1)\n",
        "# 출력층을 만들기 위해 두번째 가중치와 편향을 적용하여 최종 모델을 만듭니다.\n",
        "# 최종적인 아웃풋을 계산합니다.\n",
        "# 히든레이어에 두번째 가중치 W2[10,3]와 편향 b2[3]를 적용하여 최종적으로 3개의 출력값을 만들어냅니다.\n",
        "model = tf.add(tf.matmul(L1, W2), b2)\n",
        "\n",
        "# 마지막으로 손실함수를 작성합니다.\n",
        "# 텐서플로우에서 기본적으로 제공되는 크로스 엔트로피 함수를 이용해 복잡한 수식을 사용하지\n",
        "# 않고도 최적화를 위한 비용 함수를 다음처럼 간단하게 적용할 수 있습니다.\n",
        "cost = tf.reduce_mean(\n",
        " tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=model))\n",
        "# 최적화 함수로 AdamOptimizer를 사용한다.\n",
        "# 사용하는 최적화 함수에 따라 정확도나 학습 속도가 많이 달라질 수 있으며, AdamOptimizer는\n",
        "# 앞에서 사용한 GrdadientDescentOptimizer보다 보편적으로 성능이 좋다고 알려져 있습니다.\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "train_op = optimizer.minimize(cost)\n",
        "\n",
        "#####################\n",
        "# 신경망 모델 학습\n",
        "#####################\n",
        "# 텐서플로의 세션을 초기화\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "# 위에서 구성한 특징과 레이블 데이터를 이용해 100번 학습을 진행\n",
        "for step in range(100):\n",
        "  sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
        "  # 학습 도중에 10번에 한번씩 손실값을 출력함\n",
        "  if (step + 1) % 10 == 0:\n",
        "    print(step + 1, sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
        "\n",
        "##############################\n",
        "# 결과 확인\n",
        "# 0: 기타 1: 포유류, 2: 조류\n",
        "##############################\n",
        "# 예측값과 실제값 출력\n",
        "prediction = tf.argmax(model, 1)\n",
        "target = tf.argmax(Y, 1)\n",
        "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
        "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
        "# 정확도 출력\n",
        "is_correct = tf.equal(prediction, target)\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n",
            "WARNING:tensorflow:From <ipython-input-13-4c85d9532527>:67: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "10 0.774071\n",
            "20 0.5511784\n",
            "30 0.39220735\n",
            "40 0.27321318\n",
            "50 0.18576427\n",
            "60 0.12577209\n",
            "70 0.086964674\n",
            "80 0.06232192\n",
            "90 0.046546638\n",
            "100 0.036067728\n",
            "예측값: [0 1 2 0 0 2]\n",
            "실제값: [0 1 2 0 0 2]\n",
            "정확도: 100.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am3DzcRfH5iy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "8b2c82ec-7e3c-4a85-af35-a62bbd4b9c37"
      },
      "source": [
        "#CNN.py\n",
        "\n",
        "# MNIST데이터를 신경망 모델인 CNN 을 이용하여 더 높은 인식률을 만들어봅니다.\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# MNIST 데이터를 /mnist/data 폴더에 다운로드 받는다.\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
        "\n",
        "####################\n",
        "# 신경망 모델 구성\n",
        "####################\n",
        "# 기존 모델에서는 입력 값을 28x28 하나의 차원으로 구성하였으나,\n",
        "# CNN 모델을 사용하기 위해 2차원 평면과 특성치의 형태를 갖는 구조로 만듭니다.\n",
        "# X의 첫번째 차원인 None은 입력 데이터의 갯수\n",
        "# X의 마지막 차원인 1은 특징의 갯수로, MNIST데이터는 회색조 이미지라 채널에 색상이 1개 뿐이므로 1을 사용함\n",
        "# Y의 첫번째 차원인 None은 출력 데이터의 갯수, 10개의 분류\n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32) # 드롭아웃을 설정하기 위해서 사용\n",
        "\n",
        "# 1. 첫 번째 컨볼루션 계층을 구성\n",
        "# : 3 * 3 크기의 커널을 가진 컨볼루션 계층\n",
        "# 각각의 변수와 레이어는 다음과 같은 형태로 구성됩니다.\n",
        "# W1 [3 3 1 32] -> [3 3]: 커널 크기, 1: 입력값 X 의 특성수, 32: 필터 갯수\n",
        "# L1 Conv shape=(?, 28, 28, 32)\n",
        "# Pool ->(?, 14, 14, 32)\n",
        "# 커널에 사용할 가중치 변수\n",
        "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
        "# tf.nn.conv2d 를 이용해 한칸씩 움직이는 컨볼루션 레이어를 쉽게 만들 수 있습니다.\n",
        "# padding='SAME' 은 커널 슬라이딩시 최외곽에서 한칸 밖으로 더 움직이는 옵션\n",
        "# 입력층 X와 첫 번째 계층의 가중치 W1을 가지고, 오른쪽과 아래쪽으로 한 칸씩 움직이는 32개의 커널을 가진\n",
        "# 첫 번째 컨볼루션 계층을 만드는 코드\n",
        "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
        "L1 = tf.nn.relu(L1)\n",
        "# 첫 번째 풀링 계층\n",
        "# Pooling 역시 tf.nn.max_pool 을 이용하여 쉽게 구성할 수 있습니다.\n",
        "# 위에서 만든 컨볼루션 계층을 입력층으로 사용하고, 커널크기는 2*2로 하는 풀링 계층을 만든다.\n",
        "# strides=[1, 2, 2, 1]값은 슬라이딩 시 두 칸씩 움직이겠다는 옵션\n",
        "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "# 2. 두 번째 컨볼루션 계층을 구성\n",
        "# 3 * 3 크기의 커널 64개로 구성된 컨볼루션 계층과 2 * 2 크기의 풀링 계층으로 구성\n",
        "# L2 Conv shape=(?, 14, 14, 64)\n",
        "# Pool ->(?, 7, 7, 64)\n",
        "# W2 의 [3, 3, 32, 64] 에서 32 는 L1 에서 출력된 W1 의 마지막 차원, 필터의 크기 입니다.\n",
        "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "L2 = tf.nn.relu(L2)\n",
        "# 두 번째 풀링 계층\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "# L2 = tf.nn.dropout(L2, keep_prob)\n",
        "\n",
        "# 3. 완전 연결 계층(Fully Connected Layer)\n",
        "# 추출한 특징들을 이용해 10개의 분류를 만들어내는 계층을 구성\n",
        "# 완전 연결 계층(Fully Connected Layer): 입력값 7x7x64 -> 출력값 256\n",
        "# Full connect를 위해 직전의 Pool 사이즈인 (?, 7, 7, 64) 를 참고하여 차원을 줄여줍니다.\n",
        "# Reshape ->(?, 256)\n",
        "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
        "# 직전의 풀링 계층 크기가 7*7*64이므로, 먼저 tf.reshape 함수를 이용해 7*7*64크기의 1차원\n",
        "# 계층으로 차원을 줄인다.\n",
        "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
        "L3 = tf.matmul(L3, W3)\n",
        "L3 = tf.nn.relu(L3)\n",
        "# 과적합을 막아주는 드롭아웃 기법을 적용\n",
        "L3 = tf.nn.dropout(L3, keep_prob)\n",
        "\n",
        "# 4. 신경망 모델 구성의 마지막으로, 최종 출력값 L3 에서의 출력 256개를 입력값으로 받아서\n",
        "# 최종 출력값인 0~9 레이블을 갖는 10개의 출력값을 만듭니다.\n",
        "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L3, W4)\n",
        "# 비용 함수\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
        "# 최적화 함수 : AdamOptimizer() 함수\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "# 최적화 함수를 RMSPropOptimizer 로 바꿔서 결과를 확인해봅시다.\n",
        "# optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
        "\n",
        "#####################\n",
        "# 신경망 모델 학습\n",
        "#####################\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "print('total_batch:', total_batch) #total_batch : 550\n",
        "\n",
        "# 15회 학습\n",
        "for epoch in range(15):\n",
        "  total_cost = 0\n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    # 이미지 데이터를 CNN 모델을 위한 자료형태인 [28 28 1] 의 형태로 재구성합니다.\n",
        "    batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
        "    _, cost_val = sess.run([optimizer, cost]\n",
        "                           ,feed_dict = {X: batch_xs,Y: batch_ys, keep_prob: 0.7}) # keep_prob을 0.7로 설정하면 랜덤하게 30% 노드를 드롭\n",
        "    total_cost += cost_val\n",
        "  print('Epoch:', '%04d' %(epoch + 1), 'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
        "print('최적화 완료!')\n",
        "\n",
        "##############\n",
        "# 결과 확인\n",
        "##############\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도:', sess.run(accuracy\n",
        "                       , feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1), Y: mnist.test.labels, keep_prob: 1}))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From <ipython-input-14-9fb4360a1746>:63: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "total_batch: 550\n",
            "Epoch: 0001 Avg. cost = 0.341\n",
            "Epoch: 0002 Avg. cost = 0.102\n",
            "Epoch: 0003 Avg. cost = 0.072\n",
            "Epoch: 0004 Avg. cost = 0.056\n",
            "Epoch: 0005 Avg. cost = 0.044\n",
            "Epoch: 0006 Avg. cost = 0.038\n",
            "Epoch: 0007 Avg. cost = 0.034\n",
            "Epoch: 0008 Avg. cost = 0.029\n",
            "Epoch: 0009 Avg. cost = 0.027\n",
            "Epoch: 0010 Avg. cost = 0.022\n",
            "Epoch: 0011 Avg. cost = 0.020\n",
            "Epoch: 0012 Avg. cost = 0.017\n",
            "Epoch: 0013 Avg. cost = 0.017\n",
            "Epoch: 0014 Avg. cost = 0.016\n",
            "Epoch: 0015 Avg. cost = 0.015\n",
            "최적화 완료!\n",
            "정확도: 0.9901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J8ozZmuWTJQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "3a41f287-8391-4da6-bfde-745064806d28"
      },
      "source": [
        "#cifar10_classification.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#1.CIFAR-10 데이터를 다운로드 받기 위한 keras의 helper 함수인 load_data 함수를 임포트\n",
        "from tensorflow.keras.datasets.cifar10 import load_data\n",
        "\n",
        "#2.데이터를 배치 갯수만큼 끊어서 읽어올 수 있는 유틸리티 함수인 next_batch()함수 정의\n",
        "# 다음 배치를 읽어오기 위한 next_batch 유틸리티 함수를 정의합니다.\n",
        "def next_batch(num, data, labels):\n",
        "  # num 개수 만큼의 랜덤한 샘플들과 레이블들을 리턴합니다.\n",
        "  idx = np.arange(0 , len(data))\n",
        "  np.random.shuffle(idx)\n",
        "  idx = idx[:num]\n",
        "  data_shuffle = [data[ i] for i in idx]\n",
        "  labels_shuffle = [labels[ i] for i in idx]\n",
        "  \n",
        "  return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
        "\n",
        "#3.CNN 모델을 정의합니다.\n",
        "# CNN은 5개의 컨볼루션층과 3개의 풀링층, 2개의 완전 연결층으로 구성\n",
        "def build_CNN_classifier(x):\n",
        "  # 입력 이미지\n",
        "  x_image = x\n",
        "  # 첫번째 convolutional layer - 하나의 RGB 이미지를 64개의 특징들(feature)으로 맵핑(maping)합니다.\n",
        "  W_conv1 = tf.Variable(tf.truncated_normal(shape=[5, 5, 3, 64], stddev=5e-2))\n",
        "  b_conv1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "  h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1)\n",
        "  \n",
        "  # 첫번째 Pooling layer\n",
        "  h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "  \n",
        "  # 두번째 convolutional layer - 64개의 특징들(feature)을 64개의 특징들(feature)로 맵핑(maping)합니다.\n",
        "  W_conv2 = tf.Variable(tf.truncated_normal(shape=[5, 5, 64, 64], stddev=5e-2))\n",
        "  b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "  h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2)\n",
        "  \n",
        "  # 두번째 pooling layer.\n",
        "  h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "  \n",
        "  # 세번째 convolutional layer\n",
        "  W_conv3 = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], stddev=5e-2))\n",
        "  b_conv3 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "  h_conv3 = tf.nn.relu(tf.nn.conv2d(h_pool2, W_conv3, strides=[1, 1, 1, 1], padding='SAME') + b_conv3)\n",
        "  \n",
        "  # 네번째 convolutional layer\n",
        "  W_conv4 = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=5e-2))\n",
        "  b_conv4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "  h_conv4 = tf.nn.relu(tf.nn.conv2d(h_conv3, W_conv4, strides=[1, 1, 1, 1], padding='SAME') + b_conv4)\n",
        "  \n",
        "  # 다섯번째 convolutional layer\n",
        "  W_conv5 = tf.Variable(tf.truncated_normal(shape=[3, 3, 128, 128], stddev=5e-2))\n",
        "  b_conv5 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "  h_conv5 = tf.nn.relu(tf.nn.conv2d(h_conv4, W_conv5, strides=[1, 1, 1, 1], padding='SAME') + b_conv5)\n",
        "  \n",
        "  # Fully Connected Layer 1 - 2번의 downsampling 이후에, 우리의 32x32 이미지는\n",
        "  # 8x8x128 특징맵(feature map)이 됩니다.\n",
        "  # 이를 384개의 특징들로 맵핑(maping)합니다.\n",
        "  W_fc1 = tf.Variable(tf.truncated_normal(shape=[8 * 8 * 128, 384], stddev=5e-2))\n",
        "  b_fc1 = tf.Variable(tf.constant(0.1, shape=[384]))\n",
        "  h_conv5_flat = tf.reshape(h_conv5, [-1, 8*8*128])\n",
        "  h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
        "  \n",
        "  # Dropout - 모델의 복잡도를 컨트롤합니다. 특징들의 co-adaptation을 방지합니다.\n",
        "  h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
        "  \n",
        "  # Fully Connected Layer 2 - 384개의 특징들(feature)을 10개의 클래스-airplane, automobile, bird...-로 맵핑(maping) 합니다.\n",
        "  W_fc2 = tf.Variable(tf.truncated_normal(shape=[384, 10], stddev=5e-2))\n",
        "  b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
        "  logits = tf.matmul(h_fc1_drop,W_fc2) + b_fc2\n",
        "  y_pred = tf.nn.softmax(logits)\n",
        "  \n",
        "  return y_pred, logits # def build_CNN_classifier(x) 함수 끝\n",
        "\n",
        "#4. 인풋 데이터, 아웃풋 데이터와 드롭아웃에서 드롭하지 않고 유지할 노드 비율인 keep_prob\n",
        "# 플레이스홀더 정의\n",
        "# 인풋 아웃풋 데이터, 드롭아웃 확률을 입력받기위한 플레이스홀더를 정의합니다.\n",
        "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
        "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "#5.load_data()함수를 이용해서 CIFAR-10 데이터를 다운로드하고 tf.one_hot API를 이용해서\n",
        "# 스칼라값 형태의 레이블(0~9)을 one-hot-encoding 형태로 변환\n",
        "# CIFAR-10 데이터를 다운로드하고 데이터를 불러옵니다.\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "# scalar 형태의 레이블(0~9)을 One-hot Encoding 형태로 변환합니다.\n",
        "y_train_one_hot = tf.squeeze(tf.one_hot(y_train, 10),axis=1)\n",
        "y_test_one_hot = tf.squeeze(tf.one_hot(y_test, 10),axis=1)\n",
        "\n",
        "#6.build_CNN_classifier()함수를 이용해서 CNN 그래프를 선언하고, 크로스 엔트로피 손실함수와\n",
        "# 0.001의 러닝레이터를 가진 RMSProp 옵티마이저를 선언\n",
        "# Convolutional Neural Networks(CNN) 그래프를 생성합니다.\n",
        "y_pred, logits = build_CNN_classifier(x)\n",
        "# Cross Entropy를 비용함수(loss function)으로 정의하고, RMSPropOptimizer를 이용해서 비용 함수를\n",
        "# 최소화합니다.\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
        "train_step = tf.train.RMSPropOptimizer(1e-3).minimize(loss)\n",
        "#7.정확도를 계산하는 연산을 추가합니다.\n",
        "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "#8.가설, 손실함수, 옵티마이저를 정의했으니, 세션을 열어 그래프를 실행해서 학습을 진행한다.\n",
        "# 세션을 열어 실제 학습을 진행합니다.\n",
        "with tf.Session() as sess:\n",
        "  # 모든 변수들을 초기화한다.\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  # 10000 Step만큼 최적화를 수행합니다.\n",
        "  for i in range(10000):\n",
        "    batch = next_batch(128, x_train, y_train_one_hot.eval())\n",
        "    # 100 Step마다 training 데이터셋에 대한 정확도와 loss를 출력합니다.\n",
        "    if i % 100 == 0:\n",
        "      train_accuracy = accuracy.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
        "      loss_print = loss.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
        "      print(\"반복(Epoch): %d, 트레이닝 데이터 정확도: %f, 손실 함수(loss): %f\" % (i, train_accuracy, loss_print))\n",
        "    # 20% 확률의 Dropout을 이용해서 학습을 진행합니다.\n",
        "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1], keep_prob: 0.8})\n",
        "  # with tf.Session() as sess: 에 들여쓰기 맞추기\n",
        "  # 학습이 끝나면 테스트 데이터(10000개)에 대한 정확도를 출력합니다.\n",
        "  test_accuracy = 0.0\n",
        "  for i in range(10):\n",
        "    test_batch = next_batch(1000, x_test, y_test_one_hot.eval())\n",
        "    test_accuracy = test_accuracy + accuracy.eval(feed_dict={x: test_batch[0], y: test_batch[1], keep_prob: 1.0})\n",
        "    test_accuracy = test_accuracy / 10;\n",
        "  print(\"테스트 데이터 정확도: %f\" % test_accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "반복(Epoch): 0, 트레이닝 데이터 정확도: 0.125000, 손실 함수(loss): 89.252167\n",
            "반복(Epoch): 100, 트레이닝 데이터 정확도: 0.156250, 손실 함수(loss): 2.307549\n",
            "반복(Epoch): 200, 트레이닝 데이터 정확도: 0.375000, 손실 함수(loss): 1.981418\n",
            "반복(Epoch): 300, 트레이닝 데이터 정확도: 0.320312, 손실 함수(loss): 1.918704\n",
            "반복(Epoch): 400, 트레이닝 데이터 정확도: 0.414062, 손실 함수(loss): 1.572350\n",
            "반복(Epoch): 500, 트레이닝 데이터 정확도: 0.515625, 손실 함수(loss): 1.370695\n",
            "반복(Epoch): 600, 트레이닝 데이터 정확도: 0.468750, 손실 함수(loss): 1.414789\n",
            "반복(Epoch): 700, 트레이닝 데이터 정확도: 0.578125, 손실 함수(loss): 1.183807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-76afa5a0335f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"반복(Epoch): %d, 트레이닝 데이터 정확도: %f, 손실 함수(loss): %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_print\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# 20% 확률의 Dropout을 이용해서 학습을 진행합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0;31m# with tf.Session() as sess: 에 들여쓰기 맞추기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;31m# 학습이 끝나면 테스트 데이터(10000개)에 대한 정확도를 출력합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC2S5UeZaqH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<!doctype html>\n",
        "<html>\n",
        "<head>\n",
        " <title>TF.js Test</title>\n",
        " <script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@0.6.1\"></script>\n",
        " <script type=\"text/javascript\">\n",
        " // 선형회귀 모델 생성\n",
        " const model = tf.sequential();\n",
        " model.add(tf.layers.dense({units: 1, inputShape: [1]}));\n",
        " // 학습을 위한 준비 : 손실 함수와 최적화 함수를 설정\n",
        " model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n",
        " // 학습 데이터 생성\n",
        " const xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);\n",
        " const ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);\n",
        " // 데이터를 사용해서 학습\n",
        " model.fit(xs, ys).then(() => {\n",
        " // 학습된 모델을 가지고 추론\n",
        " model.predict(tf.tensor2d([5], [1, 1])).print();\n",
        " });\n",
        " </script>\n",
        "</head>\n",
        "<body>\n",
        " 콘솔을 확인하세요.\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "375N55hFarum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}